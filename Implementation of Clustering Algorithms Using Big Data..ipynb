{"cells":[{"cell_type":"code","source":["from pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Import Libraries","showTitle":true,"inputWidgets":{},"nuid":"ba76ea0d-c0c7-4d41-a0df-681013739c69"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dataset = spark.read.format(\"libsvm\").load(\"/FileStore/tables/sample_kmeans_data.txt\")\ndataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"loading dataset","showTitle":true,"inputWidgets":{},"nuid":"e5d5b31a-30cb-4cc2-aa86-67d780bd6d64"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[3]: DataFrame[label: double, features: vector]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[3]: DataFrame[label: double, features: vector]"]}}],"execution_count":0},{"cell_type":"code","source":["kmeans= KMeans().setK(2).setSeed(1)\nmodel=kmeans.fit(dataset)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Training K-means model","showTitle":true,"inputWidgets":{},"nuid":"cefa4d11-2a2b-40f4-804a-5a94c97c4801"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["predictions = model.transform(dataset)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Make predictions","showTitle":true,"inputWidgets":{},"nuid":"b2681524-ee89-4104-84cd-3912a96b10e1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["evaluator = ClusteringEvaluator()\nsilhouette = evaluator.evaluate(predictions)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Evaluate clustering by computing Silhouette score","showTitle":true,"inputWidgets":{},"nuid":"2dbd1b9d-1a0d-4bd0-a8f9-0d18db5261bb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Silhouette with squared euclidean distance = 0.9997530305375207\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Silhouette with squared euclidean distance = 0.9997530305375207\n"]}}],"execution_count":0},{"cell_type":"code","source":["centers = model.clusterCenters()\nprint(\"Cluster Centers: \")\nfor center in centers:\n    print(center)\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Shows the result.","showTitle":true,"inputWidgets":{},"nuid":"68deb029-6b9a-48a5-abbe-09207497751a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Cluster Centers: \n[9.1 9.1 9.1]\n[0.1 0.1 0.1]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Cluster Centers: \n[9.1 9.1 9.1]\n[0.1 0.1 0.1]\n"]}}],"execution_count":0},{"cell_type":"code","source":["#LDA is implemented as an Estimator that supports both EMLDAOptimizer and OnlineLDAOptimizer, and generates a LDAModel as the base model. Expert users may cast a LDAModel generated by EMLDAOptimizer to a DistributedLDAModel if needed."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"performing clustering now using LDA(Latent Dirichlet allocation )","showTitle":true,"inputWidgets":{},"nuid":"cccae722-6359-4fb6-9ae8-71ab3ff4e811"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.clustering import LDA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"importing  Library","showTitle":true,"inputWidgets":{},"nuid":"f986b61f-0adc-45a9-927c-b2af039faac6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dataset=spark.read.format(\"libsvm\").load(\"dbfs:/FileStore/shared_uploads/salomi0030@gmail.com/sample_lda_libsvm_data.txt\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Loads data.","showTitle":true,"inputWidgets":{},"nuid":"ba716871-fc23-4ccb-94d4-2293aec411e5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["lda = LDA(k=10, maxIter=10)\nmodel = lda.fit(dataset)\n\nll = model.logLikelihood(dataset)\nlp = model.logPerplexity(dataset)\n\nprint(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\nprint(\"The upper bound on perplexity: \" + str(lp))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Training LDA model.","showTitle":true,"inputWidgets":{},"nuid":"b9b18445-97b6-4b3b-9539-c8771a35b445"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["topics = model.describeTopics(3)\nprint(\"The topics described by their top-weighted terms:\")\ntopics.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Describe topics.","showTitle":true,"inputWidgets":{},"nuid":"b0ec15ea-cc2d-4e8d-b07c-35fc26808b40"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["transformed = model.transform(dataset)\ntransformed.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":" result","showTitle":true,"inputWidgets":{},"nuid":"b873e43a-ef22-4a98-be21-76cbd9144d19"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Implementation of Clustering Algorithms Using Big Data.","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4052307809996952}},"nbformat":4,"nbformat_minor":0}
